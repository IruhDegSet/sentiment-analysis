{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preparation using vectorizer\n",
    "in this notebook we will use the sklearn vectorizer and bag of words\n",
    "## Bag of words\n",
    "bag of words, \"bow\", is a technic where we extract words from text as features, and ake from those words vectors \n",
    "*for example*:\n",
    "- \"this is good\"\n",
    "- \"good day\"\n",
    "- \"this is a long day\"\\\n",
    "when we vectorize those lines of text we get a bag of words which will contain a list of words **[this, is, good, day, a, long]** and for each line of the text the vectorizer will attribute the number of occurences of the word in the sentence\n",
    "the vectorizer out put will be:\\\n",
    "- [1 1 1 0 0 0]\n",
    "- [0 0 1 1 0 0]\n",
    "- [1 1 0 1 1 1]\\\n",
    "now if we try to vectorize a new line eg.:\\\n",
    "- '*this day is a good long day*'\\\n",
    "the output will be:\n",
    "- [1 1 1 2 1 1]\n",
    "\n",
    "if we enter a line with a whle new words, what will be the output?\\\n",
    "for eg.:\\\n",
    "'*I love cats*'\\\n",
    "the output: [0 0 0 0 0 0]\n",
    "\n",
    "look at it this way like a table, where the ***features*** are the words in given text and the rows contains the number of occurences in each sentence.\n",
    "| input lines | this | is | good | day | a | long|\n",
    "|:------|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| \"this is good\" | 1 | 1 | 1 | 0 | 0 | 0 |\n",
    "| \"good day\" | 0 | 0 | 1 | 1 | 0 | 0 |\n",
    "| \"this is a long day\" | 1 | 1 | 0 | 1 | 1 | 1 |\n",
    "| \"this day is a good long day\" | 1 | 1 | 2 | 1 | 1 | 1 |\n",
    "| \"I love cats\" | 0 | 0 | 0 | 0 | 0 | 0 |\n",
    "\n",
    "**Incovinients** is that order is not taken in consideration\n",
    "\n",
    "### n_grams\n",
    "the n_grams technic consists of taking n successive words instead of one word as a feature where n is the number of successive words:\n",
    "- 1_gram == monogram 1 word at a time\n",
    "- 2_grams == bigram 2 successive words at a time\n",
    "- 3_grams == trigram 3 successive words at a time\\\n",
    "this technic is used to keep sequences in dataframe\n",
    "\n",
    "with **bigram** the features will be **[this is, is good, good day, is a, a long, long day]** so the out put also will change insteade on counting the occurences of a word we will count the occurences of sub sequence\\\n",
    "the *output*:\n",
    "| line | this is | is good | good day | is a | a long | long day|\n",
    "|:------|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| \"this is good\" | 1 | 1 | 0 | 0 | 0 | 0 |\n",
    "| \"good day\" | 0 | 0 | 1 | 0 | 0 | 0 |\n",
    "| \"this is a long day\" | 1 | 0 | 0 | 1 | 1 | 1 |\n",
    "| \"this day is a good long day\" | 0 | 0 | 0 | 1 | 0 | 1 |\n",
    "| \"I love cats\" | 0 | 0 | 0 | 0 | 0 | 0 |\n",
    "\n",
    "**Incovinients** is that we loose some words if the exact same sub sequence don't appear in the new text\n",
    "\n",
    "### ngrams range\n",
    "the ngrams alone is not quite good so we use ngrams_range\\\n",
    "ngram_range is a tuple (s, e) where all the n_grams between s_gram and e_gram will be taken in consideration, inclusively\\\n",
    "ngram_range== (1, 4) --> 1_gram, 2_grams, 3_grams and 4_grams bag of words will be created\n",
    "\n",
    "for our example let's create an ngrams_range of (1,3)\\\n",
    "the bag of words will contain **[this, this is, this is good, this is a, is, is good, is a, is a long, good, good day, day, a, a long, a long day, long, long day]**\n",
    "\n",
    "the *output* table:\n",
    "| line | this| this is | this is good | this is a | is | is good | is a | is a long | good | good day | day | a | a long | a long day | long | long day |\n",
    "|:------|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| \"this is good\" | 1 | 1 | 1 | 0 | 1 | 1 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
    "| \"good day\" | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1 | 0 | 0 | 0 | 0 | 0 |\n",
    "| \"this is a long day\" | 1 | 1 | 0 | 1 | 1 | 0 | 1 | 1 | 0 | 0 | 1 | 1 | 1 | 1 | 1 | 1 |\n",
    "| \"this day is a good long day\" | 1 | 0 | 0 | 0 | 1 | 0 | 1 | 0 | 1 | 0 | 1 | 1 | 0 | 0 | 1 | 1 |\n",
    "| \"I love cats\" | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
    "\n",
    "**Inconvinients** the dataframe get larger quickly and imagine if there are spelling errors, abbreviations or sms writings like [lol, amaaaaazing, hhh, ] that will be features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "\n",
    "# for relative imports\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from src.data.text_2_dataframe import Text2DF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initalizing the vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words monogram\n",
    "CV1= Text2DF(vectorizer=True, ngrams_range= (1,1), use_wordlist= False, use_stopwords= False)\n",
    "\n",
    "# bag of words monogram using a vocabulary\n",
    "CV2= Text2DF(vectorizer=True, ngrams_range= (1,1), use_wordlist= True, use_stopwords= False)\n",
    "\n",
    "# bag of words monogram using vocabulary and avoiding stopwords\n",
    "CV3= Text2DF(vectorizer=True, ngrams_range= (1,1), use_wordlist= True, use_stopwords= True)\n",
    "\n",
    "# bag of words monogram avoiding stopwords\n",
    "CV4= Text2DF(vectorizer=True, ngrams_range= (1,1), use_wordlist= False, use_stopwords= True)\n",
    "\n",
    "# bag of words bigram\n",
    "CV5= Text2DF(vectorizer=True, ngrams_range= (2,2), use_wordlist= False, use_stopwords= False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
